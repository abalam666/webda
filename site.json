{"title":"Webda","logo":"../images/webda.svg","githubRepo":"loopingz/webda","googleAnalytics":"UA-77346317-1","index":{"title":"Home","description":"Serverless for developers ! Focus only on your code, deploy everywhere","content":" Copyright @ 2018 Webda Powered by Electric.js Sponsored by Loopingz ","srcFilePath":"src/pages/index.soy","id":"pages","location":"/./","url":"/webda/./","children":{"docs":{"title":"Docs","description":"Everything you need to know to get started.","content":" Docs Start learning how to leverage the power of . Choose a Guide Each one provide step by step coverage for every core feature. ","srcFilePath":"src/pages/docs/index.soy","id":"docs","location":"/docs/","url":"/webda/docs/","children":{"search":{"title":"Search","description":"Find what you're looking for in the documentation.","hidden":true,"content":" Webda Docs Start learning how to leverage the power of . ","srcFilePath":"src/pages/docs/search.soy","id":"search","location":"/docs/search.html","url":"/webda/docs/search.html"},"create":{"title":"Quick start","description":"How to startup a project.","layout":"guide","icon":"flash","weight":1,"class":"blue","content":" {$page.description} Installation You first need to install webda-shell. npm install -g webda-shell This will install the webda shell tools, that allows you to configure and deploy your project You have the configuration UI available, where you can create a service, use a service, or create a custom API resource. You can also manually edit the webda.config.json if you prefer Below is the manual step with the manual modification, I would recommand to use the configuration UI to modify the webda.config.json Init a project Create a new project folder mkdir my-new-project cd my-new-project If you do want to use our sample project, first type webda init Launch your project configuration interface webda config You should now see the configuration website in your browser Create a new route We will use the inline RouteHelper here, except the Lambda Route helper, the other are mainly helper for quick and easy test but you should use Service when you can as they are easier to unit test and make code cleaner. { \"*\": \"demo.webda.io\", \"demo.webda.io\": { ... \"/myurl\": { \"type\": \"inline\", \"callback\": \"function(ctx) { ctx.write('I am an inline route'); }\" } } } This is defining the GET /myurl API There is 5 types of route : file, inline, lambda, resource, string File route file include the javascript file and call its main export with the context webda.config.json { \"*\": \"demo.webda.io\", \"demo.webda.io\": { ... \"/myapi\": { \"type\": \"file\", \"file\": \"./test.js\" } } } test.js module.exports = (ctx) { ctx.write('This is my custom API') } Inline route inline eval the content of the callback string { \"*\": \"demo.webda.io\", \"demo.webda.io\": { ... \"/myurl\": { \"type\": \"inline\", \"callback\": \"function(ctx) { ctx.write('I am an inline route'); }\" } } } Lambda route lambda call a Lambda function and return its result Resource route resource return the content of the file, guessing it's mime type { \"*\": \"demo.webda.io\", \"demo.webda.io\": { ... \"/myurl\": { \"type\": \"resource\", \"file\": \"./test.jpg\" } } } This will return the jpeg with image/jpeg mime type String route string return the content of result, you can specify the mime { \"*\": \"demo.webda.io\", \"demo.webda.io\": { ... \"/myurl\": { \"type\": \"string\", \"result\": \"Hi Webda !\" } } } This will return a \"Hi Webda !\" Create a new service We will create a new service from executor, so we can map some urls directly to the service const Executor = require('webda/services/executor') class MyService extends Executor { init(config) { // Let's add our routes here, for Modda the URL should be dynamic config['/myservice'] = { method:[\"GET\", \"DELETE\"], _method: this.handleRequest, executor: this }; // This will declare two routes // GET /myservice // DELETE /myservice } delete(ctx) { // If we dont output anything, then the default result will be a 204 } get(ctx) { // Should output : I am a getter and i've sent an welcome email to you // The _params object is passed from the configuration file // You will see below the configuration file with the sentence attribute defined ctx.write(this._params.sentence); let otherService = this.getService(\"Mailer\"); otherService.send(); } handleRequest(ctx) { // As we redirect both GET and DELETE to handleRequest, we filter here if (ctx.route.http.method === \"GET\") { this.get(ctx); } else { this.delete(ctx); } } } Here is the corresponding configuration { ... services: { ... \"MyService\": { require: \"./myservice.js\", sentence: \"I am a GET route and i've sent an welcome email to you\" } ... } ... } Run it webda serve You can call the http://localhost:18080/myservice, and see the nice output \"I am a GET route and i've sent an welcome email to you\" And then the http://localhost:18080/myurl \"I am a inline route\" ","srcFilePath":"src/pages/docs/create/index.md","id":"create","location":"/docs/create/","url":"/webda/docs/create/","children":{"tutorials":{"title":"Tutorials","description":"Youtube videos to help you understand the project.","layout":"guide","icon":"flash","weight":1,"class":"blue","content":" {$page.description} Setting up a project from scratch In this video you will see: How to install Webda How to use the configurator to add services like Authentication and NoSQL Store Expose services as REST API Deploy to the cloud using the AWS deployer Add the mapping configuration to our project Creating links between objects using the map so the NoSQL data deduplication is handled for you Use our new serverless API on a Polymer interface Now that the two previous videos created an API online on Lambda and expose throught the API Gateway You can setup a nice UI using Polymer and our set of components We'll implement : Registration with email Login with email Add a contact Edit a contact Remove a contact Upload directly to S3 ","srcFilePath":"src/pages/docs/create/tutorials.md","id":"tutorials","location":"/docs/create/tutorials.html","url":"/webda/docs/create/tutorials.html"}},"childIds":["tutorials"]},"deploy":{"children":{"aws":{"title":"AWS","description":"Deploy on Lambda and API Gateway for true serveless experience.","layout":"guide","weight":1,"content":" Overview Deployment Policy To be able to deploy the deployment user must have at least : { \"Sid\": \"Stmt1438583420001\", \"Effect\": \"Allow\", \"Action\": [ \"lambda:*\", \"iam:PassRole\", \"apigateway:*\" ], \"Resource\": [ \"*\" ] } This can be restrict more and should, need to update the documentation Package The package is a zip of your folder, we dont have advanced cleaning feature nor ignore files, so the package can be big if you forget to clean your folder before. Lambda Once the package done, it will be upload as a Lambda function with the name specified, updating if it already exists. API Gateway It map all the routes from your application, if a website parameter is found on the parameters of deployment then it will enable CORS for you for this URL It also deploy the API as Stage named with the name of the deployment. ","srcFilePath":"src/pages/docs/deploy/aws.md","id":"aws","location":"/docs/deploy/aws.html","url":"/webda/docs/deploy/aws.html"},"configuration":{"title":"Configuration Resolution","description":"How Webda resolve service parameters.","layout":"guide","weight":2,"content":" {$page.description} Overview To ease up the configuration of an application we came up with the follow configuration resolution schema. You have the global configuration for the application, that is override by the deployment configuration, that is override by the local element configuration, and finally override by the deployment element configuration. This is the detail configuration for each section // Global Configuration { \"param1\": \"test1\", \"param2\": \"test2\", \"param3\": { \"subparam1\": \"subtest1\" } } // Deployment Global Configuration { \"param1\": \"deploytest1\", \"param2\": \"deplyparamtest2\" } // Service Local Configuration { \"param2\": \"localtest2\", \"param3\": { \"subparam2\": \"sublocaltest2\" } } // Service Deployment Configuration { \"param3\": { \"subparam2\": \"subdeploytest2\" } } // Service Deployment Configuration { \"param1\": \"deploytest1\", \"param2\": \"localtest2\", \"param3\": { \"subparam1\": \"subtest1\", \"subparam2\": \"subdeploytest2\" } } So this how webda will resolve Service final configuration // Step 1 - Global configuration { \"param1\": \"test1\", \"param2\": \"test2\", \"param3\": { \"subparam1\": \"subtest1\" } } // Step 2 - Deployment global configuration override { \"param1\": \"deploytest1\", \"param2\": \"deplyparamtest2\", \"param3\": { \"subparam1\": \"subtest1\" } } // Step 3 - Service local configuration override { \"param1\": \"deploytest1\", \"param2\": \"localtest2\", \"param3\": { \"subparam1\": \"subtest1\", \"subparam2\": \"sublocaltest2\" } } // Step 4 - Service deployment configuration override { \"param1\": \"deploytest1\", \"param2\": \"localtest2\", \"param3\": { \"subparam1\": \"subtest1\", \"subparam2\": \"subdeploytest2\" } } Configuration UI Here is some screenshots of the ui Routes Services Deployments ","srcFilePath":"src/pages/docs/deploy/configuration.md","id":"configuration","location":"/docs/deploy/configuration.html","url":"/webda/docs/deploy/configuration.html"},"docker":{"title":"Docker","description":"The easier way to ship software.","layout":"guide","weight":1,"content":" {$page.description} You can use webda to build your Docker image for you Dockerfile You can create your own Dockerfile, if no Dockerfile is present then the default one is used FROM node:latest MAINTAINER docker@webda.io RUN mkdir /server/ ADD . /server/ RUN cd /server && rm -rf node_modules && npm install CMD cd /server && node_modules/.bin/webda serve /data/webda.log Configuration The configuration take only two parameters the tag of the image to create and if it needs to push the image after a succesfull build. { tag: \"mytag\", push: true } ","srcFilePath":"src/pages/docs/deploy/docker.md","id":"docker","location":"/docs/deploy/docker.html","url":"/webda/docs/deploy/docker.html"},"local":{"title":"Local","description":"Run a NodeJS Express server to serve your API.","layout":"guide","weight":3,"content":" {$page.description} Overview webda serve [-d deploymentName] [--devMode] You can specify a deploymentName to serve API with the deployment configuration You can disable CORS by adding a --devMode ","srcFilePath":"src/pages/docs/deploy/local.md","id":"local","location":"/docs/deploy/local.html","url":"/webda/docs/deploy/local.html"},"wedeploy":{"title":"WeDeploy","description":"Very nice product made by our friends at Liferay, you should definitely check out.","layout":"guide","weight":3,"content":" {$page.description} Overview WeDeploy allows you to run your own Docker container without having to care about scalability or reverse proxy or monitoring As Webda allows you to deploy on Docker, we just extend the deployer to automate the call to your wedeploy shell to be completed ","srcFilePath":"src/pages/docs/deploy/wedeploy.md","id":"wedeploy","location":"/docs/deploy/wedeploy.html","url":"/webda/docs/deploy/wedeploy.html"}},"title":"Deploy","description":"Webda allow you to deploy to different environment as Docker, WeDeploy and of course Lambda.","layout":"guide","icon":"cloud","weight":4,"class":"orange","content":" {$page.description} Lambda To be able to run a 'webserver' on Lambda, you need to setup API Gateway, and configure every path defined by your code to link to your Lambda. This is how a normal deployment looks like : img But don't worry, with Webda it is as simple as a command webda deploy -d LambdaDeployment This command will do several step for you : Create the policy and role for your Lambda Create if needed the Dynamo table used in your application Create S3 buckets used in your application Deploy the code to your Lambda Create the API Gateway mapping Add permission for API Gateways to your Lambda Docker You can also just define a Docker image to build It will build the image for you with the Dockerfile specified or create a dynamic Dockerfile if not specified If you specify a tag, after the build it will push the image to your repository WeDeploy This service run your Docker image and allow you to deploy with a single command As an extend to our Docker deployment, we can build the Dockerfile and deploy it directly to your WeDeploy account. Just specify the WeDeploy Project and Service, and we will take care of the rest. ","srcFilePath":"src/pages/docs/deploy/index.md","id":"deploy","location":"/docs/deploy/","url":"/webda/docs/deploy/","childIds":["aws","docker","configuration","local","wedeploy"]},"develop":{"children":{"authentication":{"title":"Authentication","description":"Handle users and idents storage and authentication with several providers","layout":"guide","icon":"code-file","weight":2,"class":"green","content":" {$page.description} Overview The Authentication service highly depends on PassportJS this is why its file is passport.js It requires two stores : Idents and Users. The Idents will contains each mode of Authentication enabled by the user, you will find in the Ident also the profile returned by the OAuth provider if returned. The Users will have one object per user, with the idents collection, it also contains the password if any is set. Basic configuration \"successRedirect\": \"https://shootandprove.loopingz.com/user.html\", // Redirect to this page after login \"failureRedirect\": \"/login-error\", // Redirect to this page after failed login \"userStore\": \"\", // If you want to override the userStore name by default Users \"identStore\": \"\", // If you want to override the identStore name by default Idents \"providers\": { ... // See below } Register event When a user register, the Authentication service send a Register event, so you can complete the user with additional informations. // Datas is the profile coming from the OAuth or the Register form this.emit(\"Register\", {\"user\": user, \"datas\": datas, \"ctx\": ctx}); Email authentication To use this feature you need to have a configured Mailer service, you can define the service name by adding the field mailer inside the email configuration. The email authentication has two modes, one that register the user without waiting for the email validation, and the other one that register the user only when the registration form contains the right validation token sent by email. ... \"providers\": { \"email\": { \"from\": \"\", // Email sender \"subject\": \"\", // Email subject \"html\": \"\", // HTML to send by email for email validation \"text\": \"\", // Text to send by email for email validation \"mailer\": \"DefinedMailer\", // Defined mailer to use \"postValidation\": false, // If true, create user without email validation \"skipEmailValidation\": true // Don't even send a validation email, must be set along with postValidation=true }, } ... The email authentication expose POST /auth/email if the body contains register=true then it will perform registration, if not then only login returning 404 if unknown user, 403 for bad password, 204 for successful login GET /auth/callback OAuth You can setup differents types of OAuth, we integrate for now only Facebook, Amazon, Twitter, GitHub, Google. { ... providers: { facebook: { clientID: \"facebookClientId\", clientSecret: \"facebookSecret\", scope: [\"email\",\"public_profile\"] } } ... } This is the same for the other providers, except Twitter where the fields are OAuth1 : consumerKey and consumerSecret Polymer You have a Polymer behavior that implement the Authentication : ... ","srcFilePath":"src/pages/docs/develop/authentication.md","id":"authentication","location":"/docs/develop/authentication.html","url":"/webda/docs/develop/authentication.html"},"binary":{"title":"Binaries","description":"Service to store binaries and expose an API for store / retrieve","layout":"guide","icon":"code-file","weight":2,"class":"green","content":" {$page.description} Overview The storage of files is handle by those categories, we have two services FileStorage and S3Storage The API exposed is GET /binary/{store}/{uuid}/{property}/{index} PUT /binary/upload/{store}/{uuid}/{property}/{index} DELETE /binary/{store}/{uuid}/{property}/{index}/{hash} You can reduce the exposition by adding an expose attribute as on Store As you can only add a binary attached to an object stored on the system, the url reflect this : store is the Store of the object you want attached to uid is the Object uuid property is the field of the Object index is the index of the Binary hash the hash of the file to delete to ensure, if someone insert another file you don't delete the wrong file by accident Map To prevent people for adding files everywhere you specify in which object and fields you can post a file. \"map\": { \"users\": [\"s3images\"] } The above configuration will allow a user to link a binary to a user on the field s3images. So with the previous URL that means to play with binaries for a User ( uuid: user_02 ) To add PUT /binary/upload/users/user_02/s3images/add To replace PUT /binary/upload/users/user_02/s3images/0 To get GET /binary/users/user_02/s3images/0 To delete DELETE /binary/users/user_02/s3images/0/1928434324... S3Binary To configure just add the parameter bucket FileBinary To configure just add the parameter folder Polymer The behavior implementation can be found there : Two different UI component exist also : A simple fab button upload : IA paper-input with Browse button : ","srcFilePath":"src/pages/docs/develop/binary.md","id":"binary","location":"/docs/develop/binary.html","url":"/webda/docs/develop/binary.html"},"custom":{"title":"Custom","description":"A Store service is a special service that handles storage for JSON objects","layout":"guide","icon":"code-file","weight":2,"class":"green","content":" {$page.description} Overview If you need to implement a new functionality like Google Drive. You will create a service to be able to login and retrieve documents from Google Drive It can either be an internal service that has no API exposed or an external one ( from Executor ) Internal service If you need to implement a new functionality like Google Drive. You will create a service to be able to login and retrieve documents from Google Drive It can either be an internal service that has no API exposed or an external one ( from Executor ) const Service = require('webda/services/service') class MyInternalService extends Service { init() { this._gdrive = new ...; } getDocument(uuid, token) { return this._gdrive.getDocument(uuid, token); } } The GDrive API is faked here, but basically this service will allow you to get some configuration from the webda.config.json and expose some methods for others Services or Models to use inside Webda Service with exposed API const Executor = require('webda/services/executor') class MyService extends Executor { init(config) { // Let's add our routes here, for Modda the URL should be dynamic config['/myservice'] = { method:[\"GET\", \"DELETE\"], _method: this.handleRequest, executor: this }; // This will declare two routes // GET /myservice // DELETE /myservice } delete(ctx) { // If we dont output anything, then the default result will be a 204 } get(ctx) { // Should output : I am a getter and i've sent an welcome email to you // The _params object is passed from the configuration file // You will see below the configuration file with the sentence attribute defined ctx.write(this._params.sentence); let otherService = this.getService(\"Mailer\"); otherService.send(); } handleRequest(ctx) { // As we redirect both GET and DELETE to handleRequest, we filter here if (ctx.route.http.method === \"GET\") { this.get(ctx); } else { this.delete(ctx); } } } ","srcFilePath":"src/pages/docs/develop/custom.md","id":"custom","location":"/docs/develop/custom.html","url":"/webda/docs/develop/custom.html"},"mailer":{"title":"Mailer","description":"A mailer system coupled with a templating system","layout":"guide","icon":"code-file","weight":2,"class":"green","content":" {$page.description} Overview Web Application always needs to send an email at one point. The mailer service is a wrapper on top of two NodeJS library : NodeMailer and EmailTemplate It allows you to send email through SMTP, GMail, SES. It also provides Mustache templates to send email to the user with contextual informations and in his own language NodeMailer configuration to be completed Templating to be completed ","srcFilePath":"src/pages/docs/develop/mailer.md","id":"mailer","location":"/docs/develop/mailer.html","url":"/webda/docs/develop/mailer.html"},"models":{"title":"Models","description":"Implement your business logic directly in your Model","layout":"guide","icon":"code-file","weight":2,"class":"green","content":" {$page.description} Overview Model is the best way to express your business logic. Stores will use them to load/save/validate your objects and access to it. If no model are specified to a Store it will use the default CoreModel Security The model has a predefined method canAct that will be called whenever an action is trigger on an object from an external source This method return a Promise that will stop the processing if it is rejected class CoreModel { canAct(ctx, action) { if (action === 'create') { return this.canCreate(ctx); } else if (action === 'update') { return this.canUpdate(ctx); } else if (action === 'get') { return this.canGet(ctx); } else if (action === 'delete') { return this.canDelete(ctx); } } } Custom Actions The model can defined action that will be exposed by its Store class CoreModel { static getActions() { return { 'push': {method: 'POST'}, 'qrcode': {method: ['GET', 'PUT']} }; } } Store Events The model can defined behavior on store event without defining a listener The _onAction and _onActioned are not defined as the action by itself is already inside the object class CoreModel { _onSave() { // Will be called beforeSave } _onSave() { // Will be called afterSave } _onUpdate() { // Will be called beforeUpdate } _onUpdated() { // Will be called afterUpdate } _onDelete() { // Will be called afterDelete } _onDeleted() { // Will be called afterDelete } _onGet() { // Will be called when an object is retrieved } } ","srcFilePath":"src/pages/docs/develop/models.md","id":"models","location":"/docs/develop/models.html","url":"/webda/docs/develop/models.html"},"polymer":{"title":"Polymer","description":"We develop some Polymer components to ease-up the usage of your brand new API","layout":"guide","icon":"code-file","weight":2,"class":"green","content":" {$page.description} Overview The Webda project have webcomponents it implements the default Store api, the Authentication service to be completed ","srcFilePath":"src/pages/docs/develop/polymer.md","id":"polymer","location":"/docs/develop/polymer.html","url":"/webda/docs/develop/polymer.html"},"queues":{"title":"Queues","description":"A simple QueueService that allow PUT and GET on a Queue","layout":"guide","icon":"code-file","weight":2,"class":"green","content":" {$page.description} Overview This is a wrapper on AWS SQS, it also have a MemoryQueue for unit test. You can define a worker that is the method that will be called on each item of the queue, if the method fails the underlying implementation will retry it later. Worker to be completed ","srcFilePath":"src/pages/docs/develop/queues.md","id":"queues","location":"/docs/develop/queues.html","url":"/webda/docs/develop/queues.html"},"store":{"title":"Stores","description":"A Store service is a special service that handles storage for JSON objects","layout":"guide","icon":"code-file","weight":2,"class":"green","content":" {$page.description} Overview The store services allow you to store object in a NoSQL database it handles for you mapping between objects, have a security policy and check the object with JSON Schema We have currently File, DynamoDB and MongoDB storage Expose REST API Inside the configuration you can add a block for expose the store as a REST API { ... \"expose\": { \"url\": \"/storeurl\", // By default the URL is the store name in lower case \"restrict\": { \"update\": true, // Prevent the creation of an object the PUT method wont be exposed \"delete\": false // Allow delete for the object } } ... } The above configuration will end up creating the following routes: POST /storeurl GET /storeurl/[uuid] DELETE /storeurl/[uuid] You can see that by default, once the store exposed all the methods are available unless you restrict them. Configuring Mapping As an example we will use the Users / Idents stores used by the Authentication module. A User has several Idents so in NoSQL we need to deduplicate a part of the Ident object inside an array inside the User object The following is the Idents store configuration { ... \"map\": { \"Users\": { // Target store \"key\": \"user\", // Property inside Ident Object \"target\": \"idents\", // Property on the User Object \"fields\": \"type\", // Fields from the Ident Object ( uuid is added by default ) \"cascade\": true // If User object is delete then delete all the linked Idents } } So if you have a user like { ... \"uuid\": \"user_01\" } Then you save a new Ident object like { ... \"uuid\": \"ident_01\", \"user\": \"user_01\", \"type\": \"Google\" } Once the Ident saved, the User object will look like { ... \"uuid\": \"user_01\", \"idents\": [{\"uuid\":\"ident_01\",\"type\":\"Google\"}] ... } Then if you update the field type on your Ident object the User object will reflect the change, as well as if you delete the ident object it will be removed from the User object. If cascade = true, then if you delete the User object, all attached Idents will be delete aswell. Events The Stores emit events to let you implement some auto completion of the object if needed or taking any others action even deny the action by throwing an exception The store event looks like { 'object': object, 'store': this } Store.Save: Before saving the object Store.Saved: After saving the object Store.Update: Before updating the object Store.Updated: After updating the object Store.Delete: Before deleting the object Store.Deleted: After deleting the object Store.Get: When getting the object Models The store is using a Model to map your object. It allows you to implement security constraint on the object itself, add some custom actions and validation Custom actions As we saw before the store will expose your objects via an URL You can also add any specific behavior while saving / updating / deleting class MyModel extends CoreModel { canAct(context, action) { if (action === 'get') { return true; } else if (action === 'update') { return true; } else if (action === 'delete') { return true; } else if (action === 'create') { return true; } } } If not specified the Store will pick the Owner policy as default. Policies are implicit service, so you can get them with a getService(\"OwnerPolicy\"), but don't appear by default in the configuration file. That also means you can override a Policy if you want or create your own to implement your business model Owner Policy POST: Add the current user in the user field of the object PUT: Verify the current user is the user inside the user field GET: Verify the current user is the user inside the user field, or a public=true field exists on the object DELETE: Verify the current user is the user inside the user field Void policy No verification, not recommended at all Validation To ensure that the input is correct, you can setup a JSON schema this way any update or creation will verify that the object is correct. { ... \"validator\": \"schema\" ... } All the input of POST or PUT will then be validate against it. DynamoDB The DynamoDB stores requires at least accessKeyId, secretAccessKey and table For more information on DynamoDB : AWS DynamoDB MongoDB The MongoDB configuration requires a collection and a mongo parameter where mongo is the MongoDB url FileDB The FileDB only requires a folder where to store the datas. It creates it if not exists MemoryDB The MemoryDB only store the in a Map, so it will loose all the datas if you shutdown the server. It can be usefull for local cache or for some unit test Polymer You have a behavior defined for you, once added to your component you have the model property and a save/get/update/delete method for you to communicate with the API ","srcFilePath":"src/pages/docs/develop/store.md","id":"store","location":"/docs/develop/store.html","url":"/webda/docs/develop/store.html"}},"title":"Develop","description":"Webda provides you several services or you can create your own service","layout":"guide","icon":"code-file","weight":2,"class":"green","content":" {$page.description} Concepts Webda introduces some basic concepts : Service a singleton similar to Spring Bean to implement behaviors Executor is a service that provide some routes and expose API to the world Model to define your business logic Deployment an instance of the app with its own configuration The webda.config.json contains the configuration of the app, defining Services, Routes and global configuration, you can consider it as the applicationContext.xml of Spring if you prefer, with Beans=Services Stores The store services allow you to store object in a NoSQL database it handles for you mapping between objects, have a security policy and check the object with JSON Schema We have currently File, DynamoDB and MongoDB storage Learn More Binaries The storage of files is handle by those categories, we have two services FileStorage and S3Storage The storage detect duplicates and don't double store them, it also provides a Polymer component that will prevent upload of known binaries by using a challenge to speed up the upload. Learn More Models The stores use Models to load/save/validate/secure business object. The models should implement most of your business logic, while service should be technical implementation Learn More ","srcFilePath":"src/pages/docs/develop/index.md","id":"develop","location":"/docs/develop/","url":"/webda/docs/develop/","childIds":["authentication","binary","custom","mailer","models","polymer","queues","store"]}},"childIds":["create","develop","deploy","search"]},"blog":{"children":{"first-release":{"title":"Webda - Welcome to Serverless Application","description":"The goal of Webda is to have a framework that allows you to code locally and test it using a Node.JS and then deploy it automatically either to Lambda with API Gateway or by creating a Docker image with it including a NodeJS server.","date":"August 02, 2016","author":"Rémi Cattiau","layout":"blog","content":" With the revolution of cloud we got very used to IaaS. Whenever we want a server, we just call an API and here we are with a brand new server ready within minutes! But minutes were way too long for us! So, then came Docker, which made it possible to have all our environments loaded within seconds. Of course, for all this you still needed a server to run on. Two years ago, AWS came up with Lambda, where all we have to do is store the function and trigger it either by other AWS services events or by an HTTP request. Now, let’s take the example of running lots of small services, which are called only a few thousand times per month, but as we cannot predict the time when they'll be used, they are just sitting there the rest of the time. Without Lambda, we will need more than one Docker container to run these services with failover. So the idea of having the failover and scaling without having to take care of any containers or servers was a no-brainer for me. Lambda When you use Lambda and want to expose through HTTP, you discover that you can use the API Gateway of AWS. It is a nice technology but kind of complex to configure. When something goes wrong in your code, you cannot debug it as easily as when it was hosted on your machine. So, this is where the idea of Webda comes in! The Goal The goal of Webda is to have a framework that allows you to code locally and test it using a Node.JS and then deploy it automatically either to Lambda with API Gateway or by creating a Docker image with it including a NodeJS server. This way you can easily debug locally and then deploy to your AWS environment in a second. Let’s take a look at how to get started and create a new project : checkout our Quickstart Guide Resources Here are some more resources to help you: Website: webda.io Channel: Youtube ","srcFilePath":"src/pages/blog/first-release.md","id":"first-release","location":"/blog/first-release.html","url":"/webda/blog/first-release.html"},"new-website":{"title":"New Website for release v0.4.6","description":"Brand new website.","date":"December 11, 2017","author":"Rémi Cattiau","layout":"blog","content":" After some improvments since the first version of Webda, it requires a new look for its website. Thanks to Electric JS, we were able to create a whole new website way faster with those cool UI effects. The same day we are releasing the new website, we also have a fix release v0.4.6 This release includes : DynamoDB incrementAttribute with 0 fix Email storage in lower case In the next weeks, as Christmas gift we will work hard on a v0.5.0 it should includes : Better WeDeploy integration Easier queue worker deployment AWS Fargate integration Static website deployment integration ","srcFilePath":"src/pages/blog/new-website.md","id":"new-website","location":"/blog/new-website.html","url":"/webda/blog/new-website.html"}},"title":"Blog","description":"Discover all the latest about our project.","type":"blog","content":" By ","srcFilePath":"src/pages/blog/index.soy","id":"blog","location":"/blog/","url":"/webda/blog/","childIds":["new-website","first-release"]},"updates":{"title":"Updates","description":"Check out what's new","updates":[{"version":"0.5.5","major":false,"features":[{"icon":"hammer","title":"Service autoconnect","description":"Now your service auto-connect to each others","url":"https://github.com/loopingz/webda/issues/79"},{"icon":"hammer","title":"Increase unit test coverage and Sonar integration","description":"Aiming for the 80% coverage, we are almost there","url":"https://sonarcloud.io/dashboard?id=webda"}]},{"version":"0.5.0","major":true,"features":[{"icon":"hammer","title":"Deployment unit and new configuration format","description":"Now a deployment is composed of several deployment units, and the configuration file has changed but it will be migrated for you automatically."}]},{"version":"0.4.7","major":false,"features":[{"icon":"hammer","title":"DynamoDB 0 increment","description":"If you were trying to increment with a value of 0 the call would failed.","url":"https://github.com/loopingz/webda/issues/63"},{"icon":"hammer","title":"Emails now stored in lowercase","description":"To avoid any errors, emails are now always stored in lowercase.","url":"https://github.com/loopingz/webda/issues/64"}]},{"version":"0.4.0","major":true,"features":[{"icon":"hammer","title":"Models centric","description":"Now Store handle Models and leverage more internal methods from those models to implements rights and behaviors."}]}],"content":" ","srcFilePath":"src/pages/updates/index.soy","id":"updates","location":"/updates/","url":"/webda/updates/"}},"childIds":["blog","docs","updates"]},"basePath":"/webda"}